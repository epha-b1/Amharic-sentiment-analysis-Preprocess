{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset (Youtube) checkout the column names and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1471, 3),\n",
       " (1471, 3),\n",
       " Index(['sentiment', 'label', 'label_cat'], dtype='object'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"dataset/train_csv.csv\")\n",
    "df_test = pd.read_csv('dataset/test_csv.csv')\n",
    "\n",
    "df_train.shape, df_train.shape, df_train.columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character level normalization\n",
    "since amharic many characters with the same sound we should make the data consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def normalize_char_level_missmatch(input_token):\n",
    "    rep1 = re.sub('[ሃኅኃሐሓኻ]', 'ሀ', input_token)\n",
    "    rep2 = re.sub('[ሑኁዅ]', 'ሁ', rep1)\n",
    "    rep3 = re.sub('[ኂሒኺ]', 'ሂ', rep2)\n",
    "    rep4 = re.sub('[ኌሔዄ]', 'ሄ', rep3)\n",
    "    rep5 = re.sub('[ሕኅ]', 'ህ', rep4)\n",
    "    rep6 = re.sub('[ኆሖኾ]', 'ሆ', rep5)\n",
    "    rep7 = re.sub('[ሠ]', 'ሰ', rep6)\n",
    "    rep8 = re.sub('[ሡ]', 'ሱ', rep7)\n",
    "    rep9 = re.sub('[ሢ]', 'ሲ', rep8)\n",
    "    rep10 = re.sub('[ሣ]', 'ሳ', rep9)\n",
    "    rep11 = re.sub('[ሤ]', 'ሴ', rep10)\n",
    "    rep12 = re.sub('[ሥ]', 'ስ', rep11)\n",
    "    rep13 = re.sub('[ሦ]', 'ሶ', rep12)\n",
    "    rep14 = re.sub('[ዓኣዐ]', 'አ', rep13)\n",
    "    rep15 = re.sub('[ዑ]', 'ኡ', rep14)\n",
    "    rep16 = re.sub('[ዒ]', 'ኢ', rep15)\n",
    "    rep17 = re.sub('[ዔ]', 'ኤ', rep16)\n",
    "    rep18 = re.sub('[ዕ]', 'እ', rep17)\n",
    "    rep19 = re.sub('[ዖ]', 'ኦ', rep18)\n",
    "    rep20 = re.sub('[ጸ]', 'ፀ', rep19)\n",
    "    rep21 = re.sub('[ጹ]', 'ፁ', rep20)\n",
    "    rep22 = re.sub('[ጺ]', 'ፂ', rep21)\n",
    "    rep23 = re.sub('[ጻ]', 'ፃ', rep22)\n",
    "    rep24 = re.sub('[ጼ]', 'ፄ', rep23)\n",
    "    rep25 = re.sub('[ጽ]', 'ፅ', rep24)\n",
    "    rep26 = re.sub('[ጾ]', 'ፆ', rep25)\n",
    "    # Normalizing words with Labialized Amharic characters such as በልቱዋል or  በልቱአል to  በልቷል\n",
    "    rep27 = re.sub('(ሉ[ዋአ])', 'ሏ', rep26)\n",
    "    rep28 = re.sub('(ሙ[ዋአ])', 'ሟ', rep27)\n",
    "    rep29 = re.sub('(ቱ[ዋአ])', 'ቷ', rep28)\n",
    "    rep30 = re.sub('(ሩ[ዋአ])', 'ሯ', rep29)\n",
    "    rep31 = re.sub('(ሱ[ዋአ])', 'ሷ', rep30)\n",
    "    rep32 = re.sub('(ሹ[ዋአ])', 'ሿ', rep31)\n",
    "    rep33 = re.sub('(ቁ[ዋአ])', 'ቋ', rep32)\n",
    "    rep34 = re.sub('(ቡ[ዋአ])', 'ቧ', rep33)\n",
    "    rep35 = re.sub('(ቹ[ዋአ])', 'ቿ', rep34)\n",
    "    rep36 = re.sub('(ሁ[ዋአ])', 'ኋ', rep35)\n",
    "    rep37 = re.sub('(ኑ[ዋአ])', 'ኗ', rep36)\n",
    "    rep38 = re.sub('(ኙ[ዋአ])', 'ኟ', rep37)\n",
    "    rep39 = re.sub('(ኩ[ዋአ])', 'ኳ', rep38)\n",
    "    rep40 = re.sub('(ዙ[ዋአ])', 'ዟ', rep39)\n",
    "    rep41 = re.sub('(ጉ[ዋአ])', 'ጓ', rep40)\n",
    "    rep42 = re.sub('(ደ[ዋአ])', 'ዷ', rep41)\n",
    "    rep43 = re.sub('(ጡ[ዋአ])', 'ጧ', rep42)\n",
    "    rep44 = re.sub('(ጩ[ዋአ])', 'ጯ', rep43)\n",
    "    rep45 = re.sub('(ጹ[ዋአ])', 'ጿ', rep44)\n",
    "    rep46 = re.sub('(ፉ[ዋአ])', 'ፏ', rep45)\n",
    "    rep47 = re.sub('[ቊ]', 'ቁ', rep46)  # ቁ can be written as ቊ\n",
    "    rep48 = re.sub('[ኵ]', 'ኩ', rep47)  # ኩ can be also written as ኵ\n",
    "    return rep48\n",
    "\n",
    "\n",
    "df_test['sentiment'] = df_test['sentiment'].apply(\n",
    "    lambda x: normalize_char_level_missmatch(x))\n",
    "df_train['sentiment'] = df_train['sentiment'].apply(\n",
    "    lambda x: normalize_char_level_missmatch(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unnecessary symbols and emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(row, options):\n",
    "    \"\"\"Removes url, mentions, emoji and uppercase from tweets\"\"\"\n",
    "\n",
    "    if options['remove_url']:\n",
    "        row = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", row)\n",
    "\n",
    "    if options['remove_mentions']:\n",
    "        row = re.sub(\"@[A-Za-z0-9_]+\", \"\", row)\n",
    "\n",
    "    if options['demojify']:\n",
    "        emoj = re.compile(\"[\"\n",
    "                          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                          u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                          u\"\\U00002702-\\U000027B0\"\n",
    "                          u\"\\U00002702-\\U000027B0\"\n",
    "                          u\"\\U000024C2-\\U0001F251\"\n",
    "                          u\"\\U0001f926-\\U0001f937\"\n",
    "                          u\"\\U00010000-\\U0010ffff\"\n",
    "                          u\"\\u2640-\\u2642\"\n",
    "                          u\"\\u2600-\\u2B55\"\n",
    "                          u\"\\u200d\"\n",
    "                          u\"\\u23cf\"\n",
    "                          u\"\\u23e9\"\n",
    "                          u\"\\u231a\"\n",
    "                          u\"\\ufe0f\"  # dingbats\n",
    "                          u\"\\u3030\"\n",
    "                          \"]+\", re.UNICODE)\n",
    "        row = re.sub(emoj, '', row)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "clean_config = {\n",
    "    'remove_url': True,\n",
    "    'remove_mentions': True,\n",
    "    'lowercase': True,\n",
    "    'demojify': True\n",
    "}\n",
    "\n",
    "df_test['sentiment'] = df_test['sentiment'].apply(\n",
    "    clean_text, args=(clean_config,))\n",
    "df_train['sentiment'] = df_train['sentiment'].apply(\n",
    "    clean_text, args=(clean_config,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>label_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>ወይኔ ደስ ሲል</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>ዋውውውው በጣም አርፊ ነው</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>ምን ለማስተማር እንደ ፈለጋችሁ አልገባኝም ?ምን  የሚሉት አጨራረስ ነው</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>እማየ ትሙት አናዳችሁኛ</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>ምችት ይበላችው</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>ወይ ስተስጠሉ</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>በለው ጭስ ውስጤ ነው</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>መጀመሪያ ላይ ደሜ ፈልቶ ነበር አሁን ግን ደስ አይልለኝ</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>መሬት ጠብ እሚል ነገር አላየነም ያው ሙስናው ቀጥሏል ስራ አጡ ኑሮ ውድ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>ይሄ ሰውዬ ደሞ ሰው አግቶ አለማጠን አያቅም እንዴ</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentiment     label  label_cat\n",
       "358                                          ወይኔ ደስ ሲል  negative          0\n",
       "359                                   ዋውውውው በጣም አርፊ ነው  positive          2\n",
       "360      ምን ለማስተማር እንደ ፈለጋችሁ አልገባኝም ?ምን  የሚሉት አጨራረስ ነው  negative          0\n",
       "361                                     እማየ ትሙት አናዳችሁኛ  negative          0\n",
       "362                                          ምችት ይበላችው   neutral          1\n",
       "363                                           ወይ ስተስጠሉ  negative          0\n",
       "364                                      በለው ጭስ ውስጤ ነው   neutral          1\n",
       "365                መጀመሪያ ላይ ደሜ ፈልቶ ነበር አሁን ግን ደስ አይልለኝ  positive          2\n",
       "366   መሬት ጠብ እሚል ነገር አላየነም ያው ሙስናው ቀጥሏል ስራ አጡ ኑሮ ውድ...  negative          0\n",
       "367                    ይሄ ሰውዬ ደሞ ሰው አግቶ አለማጠን አያቅም እንዴ  negative          0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the tokens from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tokenizer_train = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=100, oov_token='<OOV>')\n",
    "tokenizer_train.fit_on_texts(df_train['sentiment'])\n",
    "word_index_train = tokenizer_train.word_index\n",
    "\n",
    "tokenizer_test = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=100, oov_token='<OOV>')\n",
    "tokenizer_test.fit_on_texts(df_train['sentiment'])\n",
    "word_index_test = tokenizer_test.word_index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Represent the string in numbers\n",
    "- Append 0s to the short strings to make them consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  6,  1, ...,  0,  0,  0],\n",
       "       [ 3,  1,  1, ...,  0,  0,  0],\n",
       "       [ 1,  1,  1, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [79, 79,  1, ...,  0,  0,  0],\n",
       "       [ 1, 29,  1, ...,  0,  0,  0],\n",
       "       [ 1,  1,  1, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_train = tokenizer_train.texts_to_sequences(df_train['sentiment'])\n",
    "padded_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences_train, padding='post', maxlen=100)\n",
    "\n",
    "sequences_test = tokenizer_test.texts_to_sequences(df_test['sentiment'])\n",
    "padded_test = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences_test, padding='post', maxlen=100)\n",
    "\n",
    "padded_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1471, 100), (368, 100))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train.shape, padded_test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.losses.categorical_crossentropy,\n",
    "    optimizer=tf.optimizers.SGD(),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 3s 15ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.2508 - val_loss: 0.0000e+00 - val_accuracy: 0.2092\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2576 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.2570 - val_loss: nan - val_accuracy: 0.2799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28675388040>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_train, df_train['label_cat'], epochs=50, validation_data=(\n",
    "    padded_test, df_test['label_cat']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(padded_train, df_train['label_cat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22826086956521738,\n",
       " array([[  0, 102,   1],\n",
       "        [  0,  77,   0],\n",
       "        [  0, 181,   7]], dtype=int64))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "predictions = nb_model.predict(padded_test)\n",
    "accuracy_score(df_test['label_cat'], predictions), confusion_matrix(\n",
    "    df_test['label_cat'], predictions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(padded_train, df_train['label_cat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5163043478260869,\n",
       " array([[  8,   3,  92],\n",
       "        [  1,   3,  73],\n",
       "        [  4,   5, 179]], dtype=int64))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svm_model.predict(padded_test)\n",
    "accuracy_score(df_test['label_cat'], predictions), confusion_matrix(\n",
    "    df_test['label_cat'], predictions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model for external use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "joblib.dump(svm_model, \"svm_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"የቆሸሸ ሟች ለመደበቅ እዚያ እንደቆሙ አውቃለሁ\"\n",
    "output = {\n",
    "    0: \"negative\",\n",
    "    1: \"neutral\",\n",
    "    2: \"positive\"\n",
    "}\n",
    "\n",
    "model = joblib.load(\"svm_model.pkl\")\n",
    "\n",
    "text = normalize_char_level_missmatch(text)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=100, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts([text])\n",
    "sequences = tokenizer.texts_to_sequences([text])\n",
    "padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences, padding='post', maxlen=100)\n",
    "\n",
    "output[model.predict(padded)[0]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
